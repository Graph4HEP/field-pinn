# field-pinn
this is a repo to use pinn to predict the magnetic field generated by coils

# Installation
`git clone git@github.com:Graph4HEP/field-pinn.git`

`bash requirements.sh`

# Run the code
## test run
`bash test.sh`
## submit jobs using cpu
`condor\_submit submit\_cpu\_job.condor`
## submit jobs using gpu
`condor\_submit submit\_gpu\_job.condor`
## local run
```python
python main.py --logdir ./log --experiment default_config 
               --device cpu --lr 0.001 --adjust_lr 0 
               --Nsamples 32 --Ntest 1000 --radius 1 --length 1 
               --unit 32 --Nep 10001 --Npde 256 --addBC 0 
               --standard 0 --geo cube --Btype normal
```

# Parameters introduction
```python
experiment  :  experiment name of what you want to try, usually used to do note which parameters are scaned or which optimize are applied
               (for example, you want to scan which lr can give the best result, you can give the name 'lr_scan_0.001', or you want to change the optimizer from Adam to AdamW, you can give the name 'AdamW')

device      :  on which device you want to run the code, cpu or gpu

lr          :  learning rate

adjust_lr   :  whether have a strategy to change the lr, you can modify the strategy in train.py

Nsamples    :  how many samples you want to train in a surface, the total samples will be 6*Nsamples

Ntest       :  how many test points you want to have inside the prediction region

radius      :  the radius of the coils

length      :  the side length of the prediction region

unit        :  the number of neurals in a layer

Nep         :  the number of epochs

Npde        :  the number of points inside of the prediction region to join the PDE loss calculation

addBC       :  whether add the boundary constrains

standard    :  whether to do the standardization

geo         :  field region, now only have 2 mode, cube region or slice region

Btype       :  B field type, you can add more field shape in data.py, now only have Helmholtz and parallel symmetry coils geo
```

# Structure of the code
The `main.py` is the main function to excute the code. 
It accpect many config parameters to change the setting of the training flexibly. 
It will first call the field generation function in `data.py` to produce the training and testing data. 
According to the config parameters, the code will decide whether to do the standardization.
Then it will start the training by calling `train` function in `train.py`
After the training, it will call `Eval` function in `Eval.py` to evaluate the perfermence of the training.

# Further to do 
1. try to scan the parameters to determine the best parameters

2. use more advanced PINN model or loss function (a good summary can be found at: [PINNacle](https://github.com/i207M/PINNacle))

3. add gaussion noise to the data and check the performence

